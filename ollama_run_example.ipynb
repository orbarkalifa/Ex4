{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b9157ad2-e903-4ce3-a72d-9a884cc1dd34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLaVA Response:\n",
      "  The image shows a robotic arm in a cozy kitchen environment, preparing food. However, without more context or information about what the robot is specifically doing or the specific actions it is taking, I cannot provide a detailed description of its activity. \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "\n",
    "def ask_llava_via_cli(image_path, question):\n",
    "    \"\"\"\n",
    "    Launches an Ollama CLI session using the llava:7b model,\n",
    "    sends an image and a question to the model, and captures the output.\n",
    "\n",
    "    Parameters:\n",
    "        image_path (str): Absolute path to the image file to analyze.\n",
    "        question (str): A natural language question about the image.\n",
    "\n",
    "    Returns:\n",
    "        str: The model's textual response.\n",
    "    \"\"\"\n",
    "    # Start the Ollama LLaVA process\n",
    "    process = subprocess.Popen(\n",
    "        [\"ollama\", \"run\", \"llava:7b\"],\n",
    "        stdin=subprocess.PIPE,\n",
    "        stdout=subprocess.PIPE,\n",
    "        stderr=subprocess.PIPE\n",
    "    )\n",
    "\n",
    "    # Build the prompt in CLI format (image + question)\n",
    "    prompt_image = f\"![image]({image_path})\\n\"\n",
    "    prompt_question = question + \"\\n\"\n",
    "    full_prompt = prompt_image + prompt_question\n",
    "\n",
    "    try:\n",
    "        # Send the prompt encoded as UTF-8 to avoid Windows charset issues\n",
    "        stdout, stderr = process.communicate(input=full_prompt.encode(\"utf-8\"), timeout=20)\n",
    "\n",
    "        # Decode and return the model's response\n",
    "        return stdout.decode(\"utf-8\", errors=\"replace\")\n",
    "\n",
    "    except subprocess.TimeoutExpired:\n",
    "        process.kill()\n",
    "        return \"Error: Timeout\"\n",
    "\n",
    "# ========== Example usage ==========\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Set the path to your image file\n",
    "    image_path = r\"C:\\\\Drawing_Robot Chef in Cozy Kitchen.png\"\n",
    "\n",
    "    # Write the question you want the model to answer\n",
    "    question = \"What is the robot doing in the kitchen?\"\n",
    "\n",
    "    # Run the query and print the result\n",
    "    result = ask_llava_via_cli(image_path, question)\n",
    "    print(\"LLaVA Response:\\n\", result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac1e226e-2ed7-4426-966e-9abaaf350f9a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-GenAI2005_CUDA]",
   "language": "python",
   "name": "conda-env-.conda-GenAI2005_CUDA-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}